{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理论笔记\n",
    "\n",
    "这是对 [Machine learning on Coursera](https://www.coursera.org/learn/machine-learning) 这门课的笔记（理论部分）（为了避免违反 Cousera Honor Code，「编程笔记」已经迁移到另一个仓库中）。课程由 [Andrew Ng](http://www.andrewng.org/)（吴恩达）开设。\n",
    "\n",
    "## 监督学习与无监督学习的区别\n",
    "\n",
    "区别是：训练数据是否有标记，有为监督，否则无监。\n",
    "\n",
    "- 监督学习（Supervised Learning）\n",
    "  - 回归regression（连续值变化）【例如，根据已有房价建模，预测房价】\n",
    "  - 分类classification（离散值分类）【例如，根据已有肿瘤形态特征信息与肿瘤是否恶性建模，预测一个给定形态的肿瘤是否恶性】\n",
    "- 无监督学习（Unsupervised Learning）：\n",
    "  - 聚类cluster【例如，鸡尾酒会算法，分离背景音和主要声源音；例如，根据互动而猜测社交网络】\n",
    "\n",
    "## 代价函数（Cost Function）\n",
    "\n",
    "机器学习的目标是通过训练数据不断优化假设函数 $h$，使得相应的代价函数 $J$ 最小。\n",
    "\n",
    "- 在**线性回归(Linear Regression)**问题中，我们的假设函数定义为 $h_\\theta(x) $，相应的代价函数定义为 $ J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m (h^{(i)} (x)- y^{(i)})^2 $，目标是找到使得相应的代价函数 $J(\\theta)$ 最小的 $\\theta$。\n",
    "  - 代价函数有很多种，这是其中一种\n",
    "  - 假设函数 h 是自变量（通常记为 x 或 $x^{(1)}, x^{(2)}, \\cdots$）的函数，而代价函数 J 是 h 中独立于自变量的参数的函数\n",
    "\n",
    "- 在**逻辑回归（Logistic Regression）**问题中，若将假设函数 $h_\\theta(x)$ 代入用于线性回归的代价函数形式，得到的函数 $J(\\theta)$ 对于 $\\theta$ 是一个非凸函数（non-convex function），\n",
    "\n",
    "  > 所谓凸函数（convex function），目前而言可以二次函数为例\n",
    "\n",
    "  从而有许多极值点，在此情况下用梯度下降法得到的解不一定是全局最优解。因此在逻辑回归问题中，代价函数可改变为 $ J(\\theta) = -\\sum_{i = 1}^m[y^{(i)}(log(h_\\theta(x^{(i)}))) + (1-y^{(i)})(log(1-h_\\theta(x^{(i)})))] $。这实际上是通过统计学上的**极大似然估计**计算得到的表达式。\n",
    "\n",
    "  **思考**：\n",
    "  \n",
    "  > 1. **代价函数的定义式，类似于统计学上方差定义式，两者之间是否有什么关系？**\n",
    "  > > 例如：方差（Variance）表示样本点偏离样本均值的程度，方差越小，表示该样本点越接近样本均值；而代价（Cost）越小，表示我们的假设越接近真实函数（至少在已有数据覆盖到的范围内）\n",
    "\n",
    "  > 2. **考虑到统计与机器学习的关系，还有多少机器学习的概念与统计学概念在定义类似/相关度大？**\n",
    "\n",
    "  > 3. **这些形式上的相似，是否意味着内涵上的相似？导致处理方法上的相似？**\n",
    "\n",
    "  > 4. **可能涉及的知识点包括 极大似然估计，凸优化**\n",
    "\n",
    "- 在**神经网络（Neural Network）**问题中，代价函数为 $J(\\theta)  = -\\frac{1}{m}[\\sum_{i = 1}^m \\sum_{k = 1}^K y^{(i)}_k log(h_\\Theta(x^{(i)}))_k + (1-y^{(i)})(log(1-h_\\Theta(x^{(i)}))_{k})] + \\frac{\\lambda}{2m} \\sum_{l = 1}^{L - 1} \\sum_{i = 1}^{s_l} \\sum_{j = 1}^{s_{l + 1}} (\\Theta_{ji}^{(i)})^2$；其中 $L$ 表示神经网络总层数，$s_l$ 表示第 $l$ 层的结点数，而正则化项的意思仍然是不加入那些下标为 0 的偏度单元项\n",
    " \n",
    "## 梯度下降法（Gradient Descent）\n",
    "\n",
    "> 该方法既适用于线性回归（Linear Regression）问题，又适用于逻辑回归（Logistic Regression）问题。\n",
    "> \n",
    "> 算法形式甚至一致，但由于**假设不同**（想看看 $h_\\theta(x)$ 的定义式），实际上是不同的算法。\n",
    "\n",
    "以单变量线性回归问题为例：\n",
    "\n",
    "假设代价函数 $J$ 是 $ \\theta_0 $ 与 $ \\theta_1 $ 的函数\n",
    "\n",
    "概述：\n",
    "1. 为 $ \\theta_0 $ 与 $ \\theta_1 $ 设置初值\n",
    "2. 反复更新 $ \\theta_0 $ 与 $ \\theta_1 $（每一次都**同时更新两个变量**），直到 $J(\\theta_0, \\theta_1)$ 最小\n",
    "    - $temp0 := \\theta_0 - \\alpha * \\frac{\\partial J}{\\partial \\theta_0}$\n",
    "    - $temp1 := \\theta_1 - \\alpha * \\frac{\\partial J}{\\partial \\theta_1}$\n",
    "    - $ \\theta_0 := temp0 $;\n",
    "    - $\\theta_1 := temp1 $;\n",
    "    - 这里的 $\\alpha$ 被称为「学习速率」，它决定了每次更新 $\\theta_j$ 的大小 \n",
    "\n",
    "\\***补充**：这个偏导数 $\\frac{\\partial J}{\\partial \\theta_j} = \\theta_j - \\alpha \\sum_{i = 1}^m(h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)}$ 对线性回归问题和逻辑回归问题的表达式均成立\n",
    "\n",
    "在多变量线性回归问题中：\n",
    "\n",
    "例如有如下 3 项特征（$n = 3$），训练样本数为 4（$m = 4$）\n",
    "\n",
    "房屋面积 | 房间数 | 使用年限 | 价格\n",
    "-------------|-----------|-------------|---------\n",
    "80 | 4 | 2 | 5000\n",
    "90 | 5 | 3 | 9000\n",
    "30   | 2 | 10 | 1000\n",
    "10 | 1 | 20 | 800\n",
    "\n",
    "其中，每种特征记为下标 $j$，样本序号记为上标 $(i)$，从而第 3 个样本为 $x^{(3)}$，该样本的第 2 个特征（这里是房间数）为 $x^{(3)}_2$\n",
    "\n",
    "此时的假设函数形式为 $h_\\theta(x) = \\theta_0 + \\theta_1 * x_1 + \\theta_2 * x_2 + \\theta_3 * x_3$\n",
    "\n",
    "为了方便起见，假设还有 1 个特征 $x_0$（$\\forall i, x^{(i)}_0 = 1$），那么参数 $\\theta$ 与自变量 $x$ 均可写成矩阵（列矩阵/向量）形式，即 $h_\\theta(x) = \\theta^{T}x$；如此改写后，代价函数也可以相应改写，同时把 $J$ 视为 $\\theta$ 的函数，而不是 $\\theta_1\\cdots\\theta_n$ 的函数\n",
    "\n",
    "### 【技巧】梯度下降法使用技巧之：特征缩放（Feature Scaling）\n",
    "\n",
    "为了让梯度下降法进行得更快，首先对特征值进行正规化（Normalization），即将所有特征值处以该特征的范围（最大值与最小值之差），以便使得所有特征值取值范围都在 -1 与 +1 之间；通常进行的是均值正规化（Mean Normalization），即（？形式类似或者内涵类似？。。。）统计中的标准化，不过分母的标准差 s 实际只要放入该特征的范围（最大值与最小值之差）即可，这样处理之后，所有特征值取值范围均在 -0.5 与 +0.5 之间（一般在这个范围内，即便不在，也偏离得不远）。\n",
    "\n",
    "### 【技巧】梯度下降法使用技巧之：学习速率（Learning Rate）\n",
    "\n",
    "如果梯度下降法运行正常，结果将收敛，表现为代价函数 $J(\\theta)$ 随 $\\theta$ 下降；当下降到某个时候 $J(\\theta)$ 基本持平不再改变时，结果收敛，这里的 $\\theta$ 就是我们想要的。\n",
    "\n",
    "如果梯度下降法运行结果是代价函数 $J(\\theta)$ 随 $\\theta$ 增大而增大，这表明结果发散。通常这是由于**学习速率 $\\alpha$ 过大**导致的；需要把学习速率减小（但也不能过小，否则可能收敛过慢）。\n",
    "\n",
    "## 【技巧】拟合成功的 2 个技巧：特征选择与多项式回归\n",
    "\n",
    "拟合成功的技巧之一是：根据不同情况（即实际影响输出的因素）选择不同的特征。例如同样对于房价而言，到底需要 2 个参数（例如房子沿街宽度 w、房子纵深 d），还是需要 1 个参数（例如房间面积 area = w \\* d）？恰当选择特征是拟合成功的关键之一。\n",
    "\n",
    "拟合成功的技巧之二是：在需要用非线性方程来拟合数据时，令非线性的幂为下标不同的一次项。例如当判断出数据可能拟合 3 次方程时，例如 $h_\\theta(x) = \\theta_0 + \\theta_1 * x + \\theta_2 * x^{2} + \\theta_3 * x^{3} $ 时，可令 $x_1 = x, x_2 = x^{2}, x_3 = x^{3}$。这样，待拟合函数则成为了线性形式，便可以用已知方法拟合出高次方程的未知参数（待定系数）了。\n",
    "\n",
    "## 正规方程（Normalization Equation）\n",
    "\n",
    "假设每个训练样本均有 $n$ 个特征，则第 i 个样本可由一个向量表示为：$\\begin{bmatrix}x^{(i)}_1\\\\x^{(i)}_2\\\\\\vdots\\\\x^{(i)}_n\\end{bmatrix}$\n",
    "\n",
    "构造矩阵 $X = \n",
    "\\begin{bmatrix}\n",
    "x^{(1)}_1&x^{(1)}_2&\\cdots&x^{(1)}_n\\\\\n",
    "x^{(2)}_1&x^{(2)}_2&\\cdots&x^{(2)}_n\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "x^{(m)}_1&x^{(m)}_2&\\cdots&x^{(m)}_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "则所求参数 $\\theta = (X^{T}X)^{-1}X^{T}y$\n",
    "\n",
    "### 如果 $X^{T}X$ 不可逆怎么办\n",
    "\n",
    "检查 2 项：\n",
    "\n",
    "1. 是否存在线性相关的特征？若是，减少特征\n",
    "2. 特征数(列数)是否比样本数（行数）多？若是，除了考虑减少特征，之后可能介绍的新算法（？。。。）外\n",
    "\n",
    "### 与梯度下降法的对比\n",
    "\n",
    "梯度下降法（Gradient Descent） | 正规方程法（Normal equation）\n",
    "---------------------------|---------------------------\n",
    "需要自行确定学习速率$\\alpha$|**不需要**确定学习速率，但需要计算 $(X^{T}X)^{-1}$\n",
    "需要迭代多次以求出最优解（\\*）|一次计算即可得到最优解\n",
    "在训练样本数较大时计算仍较快|时间复杂度为$O(n^{3})$，当 $n>10^{4}$时基本不考虑\n",
    "\n",
    "\\*注：使代价函数 $J(\\theta)$ 最小的 $\\theta$\n",
    "\n",
    "## 逻辑回归（Logistic Regression）\n",
    "\n",
    "### 线性回归（Linear Regression）？并不总是好用\n",
    "\n",
    "这实际上是一个分类（Classification）算法，用于标签（y）值为离散的情况。\n",
    "\n",
    "线性回归似乎能用于分类问题，例如：\n",
    "\n",
    "$$\n",
    "y =\n",
    "\\begin{cases}\n",
    "0, && x = 1, 2, 3 \\\\\n",
    "1, && x = 4, 5, 6\n",
    "\\end{cases} \n",
    "$$\n",
    "\n",
    "在这种情况下，很容易能拟合出一条直线，例如可能是 $h_\\theta(x) = \\frac{1}{6}x$，然后我们可以约定，使 $h_\\theta(x) \\le 0.5$ 的那些 $x$ 都属于 0 类，剩下的属于 1 类。\n",
    "\n",
    "但线性回归并不总是有效。有一种情况会让我们明白：例如当上述例子增加一个点 (20, 1) 时，拟合出的直线是 $h_\\theta = \\frac{1}{20}x$，但此时使 $h_\\theta(x) \\le 0.5$ 的那些 $x$ 中将有许多点不属于 0 类。\n",
    "\n",
    "那么你也许会注意到我上面使用了「约定」一词，你是不是会问：「那我们改变约定不就可以了吗？」问题是我们希望找到一种尽可能在一类问题中通用的约定。所以在这种情况下，线性回归用来解决分类问题就见得捉襟见肘了\n",
    "\n",
    "### 逻辑回归：使用 S 型函数（Sigmoid function）\n",
    "\n",
    "我们可以使用 [S 型函数（Sigmoid function）](https://en.wikipedia.org/wiki/Sigmoid_function) 作为假设函数来帮助我们分类。该模型为$g(z) = \\frac{1}{1 + e^{-z}}$，其中$z = \\theta^{T}x$，故 $g(z) = g(\\theta^{T}x) = h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^{T}x}}$\n",
    "\n",
    "> 该函数是[逻辑函数（Logistic function）](https://en.wikipedia.org/wiki/Logistic_function)的一个特例，这就是「逻辑回归」（Logistic Regression）名字的由来\n",
    "\n",
    "### 决策边界（Decision Boundary）\n",
    "\n",
    "**决策边界**就是分类边界。\n",
    "\n",
    "函数 $h_\\theta(x) = g(\\theta^{T}x) = P(y = 1|x;\\theta)$ 的意义即\n",
    "\n",
    "> 给定 $x$ 且参数为 $\\theta$ 的条件下，$y = 1$ 的概率\n",
    "\n",
    "假定 $h_\\theta(x) \\ge 0.5 \\Rightarrow y = 1; h_\\theta(x) < 0.5 \\Rightarrow y = 0$，\n",
    "\n",
    "其中\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "& &z \\ge 0 &\\Rightarrow& g(z) \\ge 0.5 \\\\\n",
    "& \\Leftrightarrow & z = \\theta^{T}x \\ge 0 &\\Rightarrow& g(\\theta^{T}x) = h_\\theta(x) \\ge 0.5 \\\\\n",
    "& \\Leftrightarrow & \\theta^{T}x \\ge 0 &\\Rightarrow& h_\\theta(x) \\ge 0.5 \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "也就是说，区域如何划分（即边界如何选取，即如何分类——我们的目标就是要找到一个合适的分类函数，由得到的点输入，输出该点对应的分类），只与参数 $\\theta$ 有关（与训练数据无关）。一旦 $\\theta$ 定下，则 $h_\\theta(x)$ 的表达式也就跟着定下，决策边界就是 $h_\\theta(x) = 0$ 对应的曲线。\n",
    "\n",
    "### 正则化（Regularization）\n",
    "\n",
    "拟合函数时，有 2 种问题可能出现：\n",
    "\n",
    "1. 欠拟合（Underfit, high bias）：例如用一次函数来拟合明显是符合二次函数分布趋势的点，训练数据集里有许多点无法被假设函数拟合\n",
    "2. 过拟合（Overfit, high variance）：精确通过训练数据集中的每一个点，但这将使假设函数对数据集以外的点预测能力降低\n",
    "\n",
    "其中，解决过拟合问题有 2 种方法：\n",
    "\n",
    "1. 减少特征（人工选择特征；利用算法自动选择）\n",
    "2. **正则化**（向代价函数 $J(\\theta)$ 中添加一些正则化项，通过对正则化项的「惩罚代价」提高，从而减少参数量级/数值，使某些参数几乎为 0，不起作用）\n",
    "\n",
    "但是应该添加哪些项目为正则化项呢？我们通常添加的是 $\\lambda\\sum_{j = 1}^m\\theta_j^{2}$，\n",
    "\n",
    "> **注意 1：正则化项目不包含 $\\theta_0$！**\n",
    "> **注意 2：$\\lambda$ 若过大，反倒可能使假设函数变为欠拟合状态**\n",
    "\n",
    "即让除了 $\\theta_0$ 以外的所有参数都参与正则化过程。\n",
    "\n",
    "> 这就意味着，使用梯度下降法（Gradient Descent）更新 $\\theta_j$ 时，$\\theta_0$ 应独立更新（其余 $\\theta_j$ 包含了正则化项目，则同时更新）\n",
    "\n",
    "正则化方法还有一个好：\n",
    "\n",
    "> 保证正规方程法（Normal Equation）中求逆矩阵的项一定是可逆（非奇异）的。\n",
    "\n",
    "在正规方程法中使用正则化方法时，\n",
    "\n",
    "$$\n",
    "\\theta = (X^{T}X + \\lambda A)^{-1}X^{T}y,\n",
    "$$\n",
    "\n",
    "其中，\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "0&0&0&\\cdots&0\\\\\n",
    "0&1&0&\\cdots&0\\\\\n",
    "0&0&1&\\cdots&0\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\ddots&\\vdots\\\\\n",
    "0&0&0&\\cdots&1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## 神经网络（Neural Network）\n",
    "\n",
    "### 为什么要用神经网络？（Why NN?）\n",
    "\n",
    "在以下 2 种情况下，使用逻辑回归等方法拟合计算量太大/不准确\n",
    "\n",
    "1. 当需要拟合的多项式太复杂时：计算量大，或不准确（例如可能出现过拟合的情况）\n",
    "2. 特征数较多时，例如训练对象是位图：计算量太大\n",
    "\n",
    "而神经网络（NN）在执行复杂的分类任务时非常有效。当然，由于其计算量较大，伴随着近年来计算技术的突破（包括硬件的支持），NN 重新开始又受到了关注。。。\n",
    "\n",
    "### （人工）神经网络的基本单位：（人工）神经元（Neuron）\n",
    "\n",
    "人工神经元是一个（一对一的）逻辑分类器，由 2 层构成：\n",
    "\n",
    "1. 输入层\n",
    "2. 输出层\n",
    "\n",
    "一种简单的示意图是：\n",
    "\n",
    "- 输入层为若干个结点 $x_i$，输出层有 1 个结点 $h_\\theta(x)$\n",
    "- 输入层的所有结点（有时可能会加上 1 个偏置单元 bias unit，即常数项）通过有向边指向输出层的那 1 个结点，边权值即为参数（在神经网络中又被称为「权重」（weight）？。。。）\n",
    "\n",
    "目前我们使用的神经元是带 S 型激励函数（Sigmoid function）的神经元。\n",
    "\n",
    "### 神经元如何组成神经网络：隐藏层（Hidden Layer）与激励（Activation）\n",
    "\n",
    "一般而言，神经网络在神经元的基础上多了若干隐藏层（Hidden Layer）。所谓「隐藏」（hidden）的意思是：其输出对用户而言是不可见的——我们只能看到最后一组激励的输出结果。\n",
    "\n",
    "这些隐藏层的结点被称为「激励」（Activation） $a^{(i)}$，每个激励结点通过一组有向边（一组参数）与上一层所有激励结点（第一层激励 $a^{(1)} = x$）联系在一起；通过这种方法，神经网络可以拟合出更复杂的假设。\n",
    "\n",
    "### 前向传播算法（Forward Propagation）/前馈神经网络（Feedforward NN）\n",
    "\n",
    "> 目的：计算假设函数输出（与反向传播 BP 比较！）[^1]\n",
    "\n",
    "「前向」的意思是：从底层（即输入层）开始，逐层向上（向输出层）输出计算结果；每一层的输入是上一层激励结点。输入与输出的关系是\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "z^{(i + 1)} = \\Theta^{(i)}a^{(i)}\\\\\n",
    "a^{(i + 1)} = g(z^{(i+1)})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "其中对矩阵 $\\Theta^{(i)}$ ：\n",
    "\n",
    "1. 其维度为 $S_{i+1} * (S_i + 1)$，$S_i$ 代表第 $i$ 层结点数（「+1」的意思是有 1 个偏置单元也产生了影响）\n",
    "2. 矩阵中的任一元素 $\\Theta^{(i)}_{m,n}$ 表示第 $i$ 层中第 $n$ 个单元对第 $i + 1$ 层中第 $m$ 个单元的影响（参数/权重）\n",
    "\n",
    "### 反向传播算法（Backpropagation）\n",
    "\n",
    "> 目的：最小化假设函数输出与真实值的偏差。做法是通过比较偏差，反向求梯度。[^1]\n",
    "\n",
    "算法过程如下：\n",
    "\n",
    "```octave\n",
    "% (0) Set \\Delta = 0\n",
    "\n",
    "for i = 1:m\n",
    "    % (1) Set a^{(1)} = x^{(i)}\n",
    "    % \n",
    "    % (2) Feedforward propagation to compute activation node of each layer:  a^{(2)}, \\cdots, a^{(L)}\n",
    "    %\n",
    "    % (3) Backpropagation to calculate gradient\n",
    "    %   (3-1)Error of last layer:\n",
    "    %        \\delta^{(L)} = a^{(L)} - y^{(i)}\n",
    "    %   (3-2)Error of all other layers:\n",
    "    %        \\delta^{(L - 1)}, \\delta^{(L - 2)}, \\cdots, \\delta^{(2)}\n",
    "    %        % Notice: end num is 2\n",
    "    %   (3-3)Update \\Delta:\n",
    "    %        \\Delta_{i, j}^{(l)} += a_j^{(l)} * \\delta_i^{(l + 1)\n",
    "    %        % Accumulation items: activation of source, multiplies by error of destination\n",
    "    % For details of formula that compute graident, please see the footnote just below.\n",
    "end\n",
    "```\n",
    "\n",
    "梯度计算公式如下:\n",
    "\n",
    "$$\n",
    "D_{i, j}^{(l)} =\n",
    "\\begin{cases}\n",
    "\\frac{1}{m} \\Delta_{i, j}^{(l)} + \\lambda \\Theta_{i, j}^{l}, & \\mbox{if } j \\ne 0 \\\\\n",
    "\\frac{1}{m} \\Delta_{i, j}^{(l)}, & \\mbox{if } j = 0\n",
    "\\end{cases}\\\\\n",
    "\\frac{\\partial}{\\partial \\Theta_{i, j}^{(l)}} J(\\Theta) = D_{i, j}^{(l)}\n",
    "$$\n",
    "\n",
    "上述公式中，累加项 $\\delta^{(l)} = \\frac{\\partial}{\\partial z_j^{l}} \\mbox{cost(i)}$，其计算方法如下所示：\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\delta^{(l)} &= (\\Theta^{(l)})^{T}\\delta^{(l + 1)} .* g\\prime(z(l)) \\\\\n",
    "&= (\\Theta^{(l)})^{T}\\delta^{(l + 1)} .* a^{(l)} .* (1 - a^{(l)})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**思考**：\n",
    "\n",
    "> 视频 Backpropagation Algorithm 中介绍的 $\\delta^{(l)}$ 算法，比起 Backpropagation Intuition 中介绍的算法，多了一个部分：$.* g\\prime(z^{(l)})$。那么**为什么后一个视频介绍中没有提及这部分**？**这个导数项是什么意义**？是因为这是在某种条件下可省略的项目，为了方便让读者建立概念，所以在后一个视频中略去吗？\n",
    "\n",
    "### 神经网络编写技巧\n",
    "\n",
    "1. 矩阵重整\n",
    "\n",
    "    在 Octave 中可使用 `reshape()` 函数，将向量重整成矩阵\n",
    "\n",
    "2. 随机初始化\n",
    "\n",
    "    若所有初始权重值相同（例如：初始化 $\\Theta^{(1)} = 0$），那么从第 2 层开始向后，实际上只训练出了 1 组参数组合（其他组合都是一样的，冗余的）。因此对第一层权重值进行初始化时必须使用随机数。\n",
    "\n",
    "3. 梯度校验\n",
    "\n",
    "    为了保证自己用梯度下降法以外的算法（例如 BP, 反向传播）计算出的 J 的偏导数是正确的，有必要**在正式用初次计算出的梯度（导数）训练模型前**，对已有梯度进行校验。校验方法是：\n",
    "    1. 用一个很小的 $\\epsilon$ 来计算出 $J(\\theta)$ 对 $\\theta_i$ 的偏导数近似值 approxGradient = $\\frac{J(\\theta_1, \\theta_2, \\cdots, \\theta_i + \\epsilon, \\cdots) - J(\\theta_1, \\theta_2, \\cdots, \\theta - \\epsilon, \\cdots)}{2\\epsilon}$\n",
    "    2. 比较 approxGradient 与已有梯度的大小，只要两者非常接近，就可以认为已有梯度计算无误\n",
    "\n",
    "### 神经网络设计流程总结\n",
    "\n",
    "(0\\. pick a network achitecture: 选择网络结构\n",
    "\n",
    "    3 layers:(mostly)\n",
    "        an input layer, \n",
    "        an output layer, \n",
    "        a hidden layer\n",
    "    more layers:(the more, the better)\n",
    "        an input layer,\n",
    "        an output layer,\n",
    "        more hidden layer\n",
    "    number of nodes:\n",
    "        input layer : dimensions of features\n",
    "        output layer: number of classes\n",
    "        hidden layer: an integral multiple of number of dimensions of features)\n",
    "\n",
    "\n",
    "randomly intialization\n",
    "\n",
    "FP:\n",
    "  a^{(1)} = x^{(i)}\n",
    "  a^{(l)}\n",
    "\n",
    "J(\\Theta)\n",
    "\n",
    "BP: (for-loop for each sample to compute the following items)\n",
    "  \\delta^{(l)}\n",
    "  \\frac{\\partial}{\\partial \\Theta^{(l)}} J(\\Theta)\n",
    "\n",
    "approxGradient for gradient checking, then disable gradient checking\n",
    "\n",
    "for i = 1:m\n",
    "    optimize the theta\n",
    "end\n",
    "\n",
    "1. 随机初始化权重\n",
    "\n",
    "2. $a^{(1)} = x^{(i)}$，然后使用 FP 计算各层 $a^{(l)}$，包括最后一层的输出 $a^{(L)} = h_\\Theta(x^{(i)})$\n",
    "\n",
    "3. 代价函数 $J(\\Theta)$ 计算\n",
    "\n",
    "4. 使用 BP 计算 $J(\\Theta)$ 对各层权重的偏导数 $\\frac{\\partial}{\\partial \\Theta^{(l)}} J(\\Theta)$\n",
    "\n",
    "5. 计算真实导数近似值 approxGradient 以校验 4. 所计算的导数是否正确\n",
    "\n",
    "    > 检查完毕后，停止校验代码！（校验代码极其慢）\n",
    "\n",
    "6. 使用梯度下降法，或用其他利用 BP 的高级优化方法来最小化代价函数 $J(\\Theta)$\n",
    "\n",
    "    > 通常，$J(\\Theta)$ 是一个非凸函数（non-convex function），所以通常得到的是**局部**最小值（而不是全局最小值）（不过据 Andrew Ng 说，这通常来说这不是什么大问题，因为这些方法一般会得到一个比较小的局部最小值）。\n",
    "\n",
    "### 神经网络应用：逻辑运算\n",
    "\n",
    "考虑到对于 S 函数 $g(z)$ 是单调递增函数，且 $g(4.6) \\approx 0.99 \\approx 1$，$g(-4.6) \\approx 0.01 \\approx 1$，我们可以通过设计神经网络的参数来实现基本的逻辑运算；并通过把逻辑运算安排在不同层，实现不同逻辑运算的复杂组合。\n",
    "\n",
    "例如我们可以通过如下方法实现逻辑与（AND）、逻辑或（OR）、逻辑非（NOT）、逻辑异或（XOR）运算：神经网络有 3 层，隐藏层的两个结点分别为底层的逻辑与（AND）运算及逻辑表达式 $(\\lnot x_1) \\land (\\lnot x_2)$ 的运算结果；以隐藏层这 2 个激励结点为输入，进行逻辑或（OR）运算，最终得到的输出结果为逻辑异或运算（XOR）表达式 $x_1 XOR x_2$\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "a^{(1)} &= x\\\\\n",
    "z^{(2)}_1 &= -30 + 20a^{(1)}_1 + 20a^{(1)}_2 &, & \\mbox{AND}\\\\\n",
    "z^{(2)}_2 &= 10 - 20a^{(1)}_1 - 20a^{(1)}_2 &, & (\\lnot x_1) \\land (\\lnot x_2)\\\\\n",
    "z^{(3)} &= -10 + 20a^{(2)}_1 + 20a^{(2)}_2 &, & \\mbox{OR}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 神经网络应用：多分类任务（Multiclass Classification）\n",
    "\n",
    "一个普通的逻辑回归/逻辑分类可用一个神经元/一个只有标量输出的神经网络来实现。需要执行多分类任务时，标量输出的神经网络将变成向量输出的神经网络，即输出层结点数由 1 变为 $n(n > 1)$.\n",
    "\n",
    "注意到对多分类神经网络而言，任一输入 $x$ 必满足下述条件之一：（设 $a^{(i)}$ 为最后一层激励结点亦即输出向量，为 $K$ 分类问题）\n",
    "\n",
    "1. $ \\sum^{j = 1}_k{a^{(i)_j}} = 1$（若输入 $x$ 在已有分类中，那么只有某个 $a^{(i)}_j = 1$，其余维度均为 0）\n",
    "2. $ \\sum^{j = 1}_k{a^{(i)_j}} = 0$（若输入 $x$ 不在已有分类中，那么 $\\forall j \\in [1, k],a^{(i)}_j = 0$）\n",
    "\n",
    "## 模型选择与评价\n",
    "\n",
    "> 问题：当我们想有理有据、而不是纯凭感觉来解决以下问题的话，该怎么做？\n",
    "> \n",
    "> - 对于同一批数据，我们要选择怎样的模型呢？例如普通的线性模型？还是包含了高次幂的模型？如果是后者，应该是怎样的多项式？\n",
    "> - 想优化模型性能时，应该选择如下参数优化中的哪些来进行？如何选择更高效？\n",
    ">    - 增加训练数据量\n",
    ">    - 增加特征项\n",
    ">    - 减少特征项\n",
    ">    - 增加正则化系数（例如过拟合 overfitting 时）\n",
    ">    - 减少正则化系数（例如欠拟合 underfitting 时）\n",
    "\n",
    "我们需要学会**「机器学习诊断法」（Machine learning diagnostic）**。\n",
    "\n",
    "### 模型选择\n",
    "\n",
    "「诊断」过程中，需要模型进行评估，以便选择合适的模型。那么，如何评估？\n",
    "\n",
    "评估的标准方法通常把已有数据分为 3 部分 7 : 3，即\n",
    "\n",
    "- 70% 作为训练集（training set），用于训练模型，训练出参数 \\theta（随机打乱后，取前 70% 作为训练集；否则，随机选 70%）\n",
    "- 30% 作为测试集（test set），用于测试模型\n",
    "\n",
    "这种方法的问题是：无法保证这样得到的模型对未知数据的泛化 generalization 效果。\n",
    "\n",
    "**我的问题**是：\n",
    "\n",
    "> 选择模型的多项式次数时，为什么不能直接用训练集数据——也就是说，为什么不能直接比较多项式次数各异的各种模型在训练集上的代价，从中选择代价最小的模型对应的多项式次数；然后再用测试集来测量泛化效果？\n",
    "\n",
    "改进方法是：通常把已有数据分为 3 部分 6 : 2 : 2，即\n",
    "\n",
    "- 60% 用于训练模型（training set），训练出参数 \\theta\n",
    "- 20% 用于交叉验证（cross-validation set），找出合适的多项式次数\n",
    "- 20% 用于测试模型（test set）\n",
    "\n",
    "\n",
    "> 注：\n",
    "> \n",
    "> - 评估线性回归模型，通常直接用代价函数 $J(\\theta)$\n",
    "> - 评估逻辑回归模型，除了 $J(\\theta)$ 外，还有一种评价函数是 0/1错分率（0/1 misclassification error）或误分类率（missclassification error）。。。公式。。。err(J) = \\frac{1}{m} = 1...if h>=0.5 but y = 0; 0...if h< 0.5 but y = 。。。\n",
    "\n",
    "### 偏差与方差：过拟合与欠拟合的判断与解决方法\n",
    "\n",
    "高偏差的状况下即欠拟合（underfitting），高方差的状况即过拟合（overfitting）：\n",
    "\n",
    "令假设函数对测试验证集（Cross-Validation，CV）数据的预测错误率为 $error_{CV}$，\n",
    "令假设函数对训练集的预测错误率为 $error_{train}$，\n",
    "\n",
    "> - 当 $error_{CV} \\gg error_{train}$ 时，为高方差（High variance），也即过拟合的情况（overfit）\n",
    "> - 当 $error_{CV} \\approx error_{train}$ 时，为高偏差（High variance），也即欠拟合的情况（underfit）\n",
    "\n",
    "若以模型的多项式次数 d 为自变量，错误率为因变量，作出 2 条曲线：\n",
    "\n",
    "- 训练集数据的代价 $J_{train}(\\theta)$ 关于 d 的函数 $error(d)_{train}$\n",
    "- 测试验证集（Cross-Validation，CV）数据的代价 $J_{CV}(\\theta)$ 关于 d 的函数 $error(d)_{CV}$\n",
    "\n",
    "那么会发现 $error(d)_{train}$ 单调递减，$error(d)_{CV}$ 则是类似开口向着因变量增加方向的二次函数的型式（向「上」）。\n",
    "图像上的左端，即双高，为高偏差（欠拟合）的情况；右端，高 $error(d)_{CV}$ 低 $error(d)_{train}$ 是高方差（过拟合）的情况。\n",
    "\n",
    "若以模型的多项式次数 $\\lambda$ 为自变量，错误率为因变量，作出 2 条曲线：\n",
    "\n",
    "- 训练集数据的代价 $J_{train}(\\theta)$ 关于 $\\lambda$ 的函数 $error(\\lambda)_{train}$\n",
    "- 测试验证集（Cross-Validation，CV）数据的代价 $J_{CV}(\\theta)$ 关于 $\\lambda$ 的函数 $error(\\lambda)_{CV}$\n",
    "\n",
    "那么会发现 $error(\\lambda)_{train}$ 单调递增，$error(\\lambda)_{CV}$ 则是类似开口向着因变量增加方向的二次函数的型式（向「上」）。\n",
    "图像上的左端，高 $error(\\lambda)_{CV}$ 低 $error(\\lambda)_{train}$ 是高方差（过拟合）的情况；右端，即双高，为高偏差（欠拟合）的情况。\n",
    "\n",
    "### 学习曲线（Learning Curves）\n",
    "\n",
    "使用学习曲线，可以有效地区分当前拟合状况属于高方差（High variance）（也即过拟合，overfit）还是高偏差（High bias）（也即欠拟合，underfit）\n",
    "\n",
    "学习曲线图中，自变量是样本数 $m$，因变量是错误率 $error$。图中同时画出 2 条曲线：$error_{train}$ 与 $error_{CV}$\n",
    "\n",
    "- 当 $error_{CV} \\gg error_{train}$ 时，即两条曲线差距较大，此时属于高方差情况；增大样本数，有助于改善拟合情况\n",
    "- 当 $error_{CV} \\approx error_{train}$ 时，即两条曲线差距较小，此时属于高偏差情况；增大样本数，对拟合情况改善作用不明显\n",
    "\n",
    "### 如何改善算法性能？\n",
    "\n",
    "高方差（High variance）时（过拟合，ovefit）的手段 | 高偏差（High bias）时（欠拟合，underfit）的手段\n",
    "----------------------------------------------|----------------------------------------------\n",
    "增加训练样本数 | -------------------\n",
    "减少特征项目数 | 增加特征项目数\n",
    "-------------| 增加多项式项\n",
    "增加正则化系数 $\\lambda$ | 减少正则化系数 $\\lambda$\n",
    "\n",
    "## 机器学习系统设计建议\n",
    "\n",
    "### 1. 快速实现算法然后改进\n",
    "\n",
    "从垃圾邮件分类器的设计出发，吴恩达建议学习者在选择模型时首先快速实现一个哪怕是粗糙的、不完美的算法（MVP？！）；然后绘制学习曲线（learning curves），参考学习曲线，或/且通过（手动对错误预测结果进行）误差分析，从而快速确定问题并决定如何改进算法。\n",
    "\n",
    "之所以一开始首先快速实现一个不完美的算法的（重要）原因是：任何机器学习算法遇到的问题，大部分情况下是差不多的。所以没必要一上来就纠结用哪个算法好。\n",
    "\n",
    "### 2. 偏斜数据问题（Skewed data）\n",
    "\n",
    "偏斜数据情况指的是：待分类数据中有一类数据所占比例远高于另一类数据所占比例（例如：99% 对 1%）\n",
    "\n",
    "在这种情况下，如何保证得到了正确率更高的结果是因为模型更好？（例如此时不管输入如何，全预测为某一种标签，这预测准确率可能回提升，但模型并不是更好而是更差）\n",
    "\n",
    "通常我们把小比例的那种标签设为 y=1。然后，根据标签为0/1，真实结果为0/1，可以有 2 * 2 = 4 种对应情况，分别是：\n",
    "\n",
    "- 真阳性，\n",
    "- 假阳性（真实为0，标记为1），\n",
    "- 假阴性（真实为1，标记为0），\n",
    "- 真阴性\n",
    "\n",
    "令\n",
    "\n",
    "- 准确率（precision, P） = 真阳性项目数/标记为1的项目数 = 真阳性项目数/（真阳性项目数 + 假阳性项目数）\n",
    "- 召回率（recall, R）    = 真阳性项目数/真实为1的项目数 = 真阳性项目数/（真阳性项目数 + 假阴性项目数）\n",
    "\n",
    "通常来说，我们希望两个指标数值都要高；但是这是矛盾的 2 个指标（其矛盾性通过标签分类的阈值来表现），所以我们需要平衡它们。\n",
    "如何衡量其「平衡性」？\n",
    "指标平均数？不行，因为这可能会被一个极端的指标带偏（例如，一个指标为0，另一个指标为1）\n",
    "所以我们采用 F1 值来衡量。F1 越高，「平衡性」越好。\n",
    "\n",
    "$$F_{1} = 2\\frac{PR}{P + R}$$\n",
    "\n",
    "（记忆：其实就是 $\\frac{1}{\\frac{1}{2P} + \\frac{1}{2R}}$    ）\n",
    "\n",
    "这里要用 3 个生动的例子来解释一下 P 与 R 的矛盾：\n",
    "\n",
    "> 第一个例子：诊断癌症与告知患者\n",
    "\n",
    "如果我们考虑到：患者一旦被告知癌症，可能会很痛苦（包括心理、包括治疗过程……），我们可能就希望：不要轻易诊断患者得癌症；一旦诊断为癌症，那么其得癌症的可能性必定极高。也就是说，这时候我们的分类阈值较高——要求 prob_1 = h(x) 即认为输入该被分到 1 类（患癌）的概率要高于 0.5（比如，假设这个阈值为 0.9），我们才把该输入分到 1 类（患癌）去。**这时 P 就比较高**（保证「真阳性」相对「标记为1」的比例较高，因为限制了「标记为1」的分类增长速度）。\n",
    "\n",
    "这种情况下，患癌概率为 0.8、0.7 等输入就会被分到 0 类去，也就是说我们会告知一个患癌概率较高的来客说 ta 不患癌。这时假阴性的比例就上升了。**这时 R 就较低**（导致「真阳性」相对「真实为1」的比例较低）。\n",
    "\n",
    "如果我们考虑到：不想让患者漏诊，我们更不希望看到患者被病痛折磨。也就是说，我们宁可把分类阈值调低，即便其患癌概率低于 0.5（比如，假设这个阈值为 0.2），我们也把该输入分到 1 类（患癌）去。**这时 P 就较低**（导致「真阳性」相对「标记为1」的比例降低，因为「标记为1」的数目大大增加了）。\n",
    "\n",
    "这种情况下，患癌概率为 0.3、0.4 等输入也会被分到 1 类去，夸张一点想，已知 100 个人里有 50 个患癌，现在我抓了 80 个人，那么相对原来只抓 50 个来说，我们漏诊的可能性降低了，R 就提高了。**这时 R 就较高**。\n",
    "\n",
    "（下两个例子方便理解就好，不要对个别文字含义上纲上线……）\n",
    "\n",
    "> 第二个例子：「疑罪从无」还是「疑罪从有\n",
    "\n",
    "「疑罪从无」是典型的高 P 低 R 情况；\n",
    "「疑罪从有」是典型的低 P 高 R 情况。\n",
    "具体理解可将「认定某人为犯罪分子」视为「诊断某人患有癌症」，都是稀有情况\n",
    "\n",
    "> 第三个例子：高考选拔制度\n",
    "\n",
    "给定一个分数，例如 680 以上才能上清北。\n",
    "把硬性录取考分定得较高，就保证被筛选进入清北的学生，出现水货的可能性较低，保证了高 P；但这意味着有些可能不是水货、不过确实有才的人没法进入清北深造，也就是说「假阴性」数目增加，R 降低了。硬性高分录取，属于高 P 低 R 情况。\n",
    "把硬性录取考分分数定得较低，增加其他评选项目（例如自主选拔录取等），那么这就让原本那些可能有才但不够擅长应试、值得进入清北深造的人增加了就读的可能性，也就是说真实有才华的人进入清北就读的比例上升了，R 提高了；但是硬性考分录取考分降低，意味着较水的人可能也有机会进入清北就读，也就是说假阳性的情况增加，降低了 P。降低考分录取，属于低 P 高 R 情况。\n",
    "\n",
    "### 3. 训练数据量问题\n",
    "\n",
    "一项经典的研究表明，几个经典算法虽然性能开始都不同，但随着数据量的增加，其性能（即预测准确度）都大大增加——也就是说，一个在数据量不够大时性能不太好的算法，在增加了大量训练数据后，性能可能会超过原本数据规模下性能更好的算法。\n",
    "\n",
    "当满足 2 个条件时，大量增加训练数据，能极大改善算法性能：\n",
    "\n",
    "1. 模型中有较多参数\n",
    "    - 这样，大量的训练数据能避免过拟合（overfit；也是高方差，high variance）\n",
    "    - 参数较少时如果出现欠拟合（underfit；也是高偏差，high bias），增加训练数据量的改善效果不明显\n",
    "2. 数据能够提供预测所需的足够多的特征信息\n",
    "    - 【判断方法】想看看，人类专家用已经给出的特征信息，能不能完成预测？\n",
    "    - 例如，根据上下文预测一个挖空的句子里要填写什么单词，一个人类英语专家是有可能做到比较好的。这就是特征信息「足够」了\n",
    "    - 例如，仅仅根据房屋占地面积，而不告知其所在地区（比如是商业中心地段还是郊区/交通不便处，比如装修如何，比如使用年限等），要求准确预测房价，这即便是一个房价预测人类高手也做不到。这就是特征信息「不够」\n",
    "\n",
    "## SVM（Support Vector Machine，支持向量机）\n",
    "\n",
    "### 1. 代价函数\n",
    "\n",
    "SVM 的假设函数也是如下形式：\n",
    "\n",
    "$h_\\theta(x) =\n",
    "\\begin{cases}\n",
    "1, & \\mbox{if} x \\ge 0 \\\\\n",
    "0, & \\mbox{if} x < 0\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "把逻辑回归的代价函数中，改为：\n",
    "\n",
    "- 2 个对数函数分别替换为 $cost_{1}$（当 y=1 时，起作用的代价是 $y*cost_{1}$） 与 $cost_{2}$（当 y=0 时，起作用的代价是 $(1 - y)*cost_{2}$）\n",
    "- 代价函数中不再取 m 个样本的均值\n",
    "- 正则化时，系数不再以 $\\lambda$ 放在正则项前，而是以 $C = \\frac{1}{\\lambda}$ 的形式放在非正则化的常规代价函数表达式前\n",
    "\n",
    "这 2 个函数的特点是：趋势与原来的对数函数类似，只是在 $z \\ge 1$（y = 1 时） 或 $z \\le -1$（y = 0 时）时代价为 0。\n",
    "相应的，优化目标则变成：\n",
    "\n",
    "- 当 y = 1 时，目标是在满足 $z = \\theta^{T}x  \\ge  1$ 的条件下尽可能优化 $\\theta$\n",
    "- 当 y = 0 时，目标是在满足 $z = \\theta^{T}x  \\le -1$ 的条件下尽可能优化 $\\theta$\n",
    "\n",
    "## 2. 大间距分类（Large margin classification）\n",
    "\n",
    "SVM 的漂亮特点之一就在于：\n",
    "\n",
    "> 经 SVM 处理的各类数据之间的「间距」（margin）是最大的。\n",
    "\n",
    "其数学原理简单解释为：利用向量内积的特点，在保证不等式成立的情况下（y = 1 时，不等式为 $z = \\theta^{T}x  \\ge 1$；y = 0 时，不等式为 $z = \\theta^{T}x  \\le -1$），增大各样本对应向量在决策边界曲线对应向量（$\\theta$）方向上的投影长度，从而减少 $\\theta$ 的欧式长度，从而优化 $\\theta$\n",
    "\n",
    "### 3. 核函数（Kernels）\n",
    "\n",
    "一般\n",
    "\n",
    "\n",
    "# 参考资料\n",
    "\n",
    "[^1]: [What is the difference between back-propagation and forward-propagation?](https://www.quora.com/What-is-the-difference-between-back-propagation-and-forward-propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
